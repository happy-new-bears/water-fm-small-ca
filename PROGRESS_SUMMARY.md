# CrossMAEå®æ–½è¿›åº¦æ€»ç»“

## æ¦‚è§ˆ
å·²æˆåŠŸåˆ›å»ºæ–°çš„ä»£ç åº“ `water_fm_small_ca`ï¼Œå®ç°CrossMAEæ¶æ„çš„å…³é”®åŸºç¡€æ”¹åŠ¨ã€‚

## âœ… Phase 0: æ¶æ„è°ƒæ•´ï¼ˆå·²å®Œæˆï¼‰

### ç›®æ ‡
å°†æ ‡å‡†MAEçš„pooled tokenæ¶æ„æ”¹ä¸ºCrossMAEçš„åºåˆ—ä¿ç•™æ¶æ„

### å®Œæˆçš„ä¿®æ”¹

#### 1. Image Encoder (`models/image_encoder.py`)
- âŒ **ç§»é™¤**: Poolingæ“ä½œï¼ˆåŸ: [B, L_visible, d_model] â†’ [B, d_model]ï¼‰
- âœ… **ä¿ç•™**: åºåˆ—è¾“å‡º [B, L_visible, d_model]
- âœ… **æ–°å¢**: åœ¨mask_infoä¸­ä¼ é€’padding_maskå’Œpositions

**å…³é”®æ”¹åŠ¨**:
```python
# åŸä»£ç  (å·²ç§»é™¤)
valid_mask = (~padding_mask).unsqueeze(-1).float()
encoder_token = (x * valid_mask).sum(dim=1) / valid_mask.sum(dim=1)
encoder_token = self.norm(encoder_token)  # [B, d_model]

# æ–°ä»£ç  (CrossMAEé£æ ¼)
x = self.norm(x)  # [B, L_visible, d_model] - ä¿ç•™åºåˆ—!
mask_info = {
    'mask': patch_mask,
    'lengths': lengths,
    'padding_mask': padding_mask,  # æ–°å¢
    'positions': positions_padded,   # æ–°å¢
}
return x, mask_info
```

#### 2. Image Decoder (`models/image_decoder.py`)
- âœ… **æ¥æ”¶**: åºåˆ—è¾“å…¥ [B, L_visible, d_model]
- â³ **Phase 0ä¸´æ—¶å¤„ç†**: Poolåºåˆ—ä¸ºå•ä¸ªtokenï¼ˆä¿æŒåŠŸèƒ½ä¸å˜ï¼‰
- ğŸ¯ **Phase 1å°†æ›¿æ¢**: ç”¨CrossAttentionæ›¿æ¢pooling

**å…³é”®æ”¹åŠ¨**:
```python
# æ¥æ”¶åºåˆ—è¾“å…¥
def forward(self, encoder_output: Tensor, mask_info: Dict):
    B, L_visible, _ = encoder_output.shape
    padding_mask = mask_info.get('padding_mask')

    # Phase 0: ä¸´æ—¶poolï¼ˆPhase 1å°†ç§»é™¤ï¼‰
    if padding_mask is not None:
        valid_mask = (~padding_mask).unsqueeze(-1).float()
        encoder_token = (encoder_output * valid_mask).sum(dim=1) / valid_mask.sum(dim=1)

    # ... å…¶ä½™ä»£ç ä¿æŒä¸å˜
```

#### 3. Vector Encoder (`models/vector_encoder.py`)
- âŒ **ç§»é™¤**: Temporal pooling
- âœ… **ä¿ç•™**: åºåˆ—è¾“å‡º [B, L_visible, d_model]
- âœ… **æ–°ç­–ç•¥**: Static attributesä½œä¸ºé¢å¤–tokenæ·»åŠ  [B, L_visible+1, d_model]

**å…³é”®æ”¹åŠ¨**:
```python
# ç§»é™¤pooling
x = self.norm(x)  # [B, max_len, d_model]

# Static attributesä½œä¸ºé¢å¤–token (Option B from plan)
static_token = self.attr_proj(static_attr).unsqueeze(1)  # [B, 1, d_model]
encoder_output = torch.cat([x, static_token], dim=1)  # [B, L_visible+1, d_model]

# æ›´æ–°padding_mask
static_padding = torch.zeros(B, 1, device=x_vec.device, dtype=torch.bool)
padding_mask_full = torch.cat([padding_mask, static_padding], dim=1)

return encoder_output, mask_info
```

#### 4. Vector Decoder (`models/vector_decoder.py`)
- âœ… **æ¥æ”¶**: åºåˆ—è¾“å…¥ [B, L_visible, d_model]
- â³ **Phase 0ä¸´æ—¶å¤„ç†**: Poolåºåˆ—ä¸ºå•ä¸ªtoken

#### 5. MultiModal MAE (`models/multimodal_mae.py`)
- âœ… **æ— éœ€ä¿®æ”¹**: æ¥å£å‘åå…¼å®¹
- âœ… **éªŒè¯**: forwardæ–¹æ³•æ­£å¸¸å·¥ä½œ

### æ¶æ„å·®å¼‚å¯¹æ¯”

| ç»´åº¦ | åŸæ¶æ„ (water_fm_small) | æ–°æ¶æ„ (water_fm_small_ca Phase 0) |
|------|------------------------|-----------------------------------|
| Encoderè¾“å‡º | [B, d_model] (pooled) | [B, L_visible, d_model] (sequence) |
| Decoderè¾“å…¥ | [B, d_model] | [B, L_visible, d_model] |
| Decoderå†…éƒ¨ | Self-attention | Self-attention (ä¸´æ—¶ï¼ŒPhase 1æ”¹ä¸ºCross-attention) |
| Static Attrs | Residual connection | Additional token |

---

## âœ… Phase 1.1: CrossAttentionå®ç°ï¼ˆå·²å®Œæˆï¼‰

### æ–°å¢æ¨¡å— (`models/layers.py`)

#### 1. CrossAttention
- âœ… Queryä»decoderï¼ŒKey/Valueä»encoder
- âœ… å‚è€ƒCrossMAE transformer_utils.py:69-108
- âœ… æ”¯æŒå¤šå¤´æ³¨æ„åŠ›
- âœ… Attention dropoutå’Œprojection dropout

**æ ¸å¿ƒé€»è¾‘**:
```python
class CrossAttention(nn.Module):
    def forward(self, x: Tensor, y: Tensor):
        """
        x: [B, N_decoder, decoder_dim] - decoder queries
        y: [B, N_encoder, encoder_dim] - encoder keys/values
        """
        q = self.q(x)  # Query from decoder
        kv = self.kv(y)  # Key, Value from encoder
        k, v = split(kv)

        attn = (q @ k.T) * scale
        attn = attn.softmax(dim=-1)
        out = attn @ v

        return self.proj(out)
```

#### 2. CrossAttentionBlock
- âœ… å¯é€‰self-attentionï¼ˆmasked tokensä¹‹é—´ï¼‰
- âœ… Cross-attentionï¼ˆmasked attend to visibleï¼‰
- âœ… FFN (MLP)
- âœ… å‚è€ƒCrossMAE transformer_utils.py:129-156

**ç»“æ„**:
```
x (decoder) --> [Optional Self-Attn] --> Cross-Attn(x, y) --> MLP --> output
                                             â†‘
                                         y (encoder)
```

---

## ğŸ”„ Phase 1: å‰©ä½™å·¥ä½œï¼ˆå¾…å®Œæˆï¼‰

### Phase 1.2: Image Decoderæ›¿æ¢ä¸ºCrossAttention
**éœ€è¦ä¿®æ”¹**:
1. ç§»é™¤ä¸´æ—¶poolingä»£ç 
2. åˆ›å»ºmasked queriesï¼ˆåªä¸ºmasked positionsï¼‰
3. ä½¿ç”¨CrossAttentionBlockæ›¿æ¢self-attention transformer
4. å®ç°per-batchå¤„ç†

**é¢„æœŸæ•ˆæœ**:
- âŒ ä¸å†pool encoder sequence
- âœ… Masked queriesç›´æ¥attend to encoder sequence
- âœ… èŠ‚çœçº¦80%è®¡ç®—é‡

### Phase 1.3: Vector Decoderæ›¿æ¢ä¸ºCrossAttention
ç±»ä¼¼Image Decoderçš„æ”¹åŠ¨

### Phase 1.4: Configé€‰é¡¹
**éœ€è¦æ·»åŠ **:
```python
# configs/mae_config.py
use_cross_attn = True  # Enable CrossAttention decoder
decoder_self_attn = False  # Optional masked self-attn
```

---

## ğŸ¯ Phase 2: WeightedFeatureMapsï¼ˆå¯é€‰ï¼Œå¾…å®Œæˆï¼‰

### Phase 2.1: å®ç°WeightedFeatureMaps
- å­¦ä¹ å¦‚ä½•ç»„åˆå¤šå±‚encoder features
- å‚è€ƒCrossMAE models_cross.py:23-40

### Phase 2.2: Encoderè¾“å‡ºå¤šå±‚
- ä¿å­˜æŒ‡å®šå±‚çš„åºåˆ—è¾“å‡º
- è¿”å›list of [B, L_visible, d_model]

### Phase 2.3: Decoderä½¿ç”¨å¤šå±‚features
- æ¯ä¸ªdecoderå±‚ç”¨ä¸åŒçš„encoder featureç»„åˆ
- å¯¹æ¯”æµ‹è¯•æ€§èƒ½æå‡

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

### Phase 0å®Œæˆåï¼ˆå½“å‰çŠ¶æ€ï¼‰:
âœ… æ¶æ„ç¬¦åˆCrossMAEï¼ˆåºåˆ—ä¿ç•™ï¼‰
âœ… ä½†ä»ç”¨self-attention
âœ… æ€§èƒ½ä¸åŸç‰ˆç›¸å½“
âœ… ä¸ºPhase 1åšå¥½å‡†å¤‡

### Phase 1å®Œæˆå:
ğŸ¯ å®Œæ•´CrossMAE
ğŸ¯ é¢„è®¡åŠ é€Ÿ 3-4å€ (22s/batch â†’ 6-8s/batch)
ğŸ¯ æ€§èƒ½ç›¸å½“æˆ–ç•¥å¥½

### Phase 2å®Œæˆå:
ğŸ¯ CrossMAE + WeightedFeatureMaps
ğŸ¯ é¢„è®¡é¢å¤–æå‡ 0.1-0.3%
ğŸ¯ å†…å­˜å¢åŠ é€‚ä¸­

---

## ğŸ“ æ–‡ä»¶å˜æ›´æ€»ç»“

### å·²ä¿®æ”¹æ–‡ä»¶:
1. âœ… `models/image_encoder.py` - ç§»é™¤poolingï¼Œä¿ç•™åºåˆ—
2. âœ… `models/image_decoder.py` - æ¥æ”¶åºåˆ—ï¼Œä¸´æ—¶pool
3. âœ… `models/vector_encoder.py` - ç§»é™¤poolingï¼Œstatic token
4. âœ… `models/vector_decoder.py` - æ¥æ”¶åºåˆ—ï¼Œä¸´æ—¶pool
5. âœ… `models/layers.py` - æ–°å¢CrossAttention, CrossAttentionBlock

### æ— éœ€ä¿®æ”¹:
- âœ… `models/multimodal_mae.py` - æ¥å£å…¼å®¹
- âœ… `train_mae.py` - æ— éœ€ä¿®æ”¹
- âœ… `datasets/` - æ— éœ€ä¿®æ”¹

---

## ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³å¯æ‰§è¡Œ:
1. **Phase 1.2-1.3**: æ›¿æ¢Decoderä¸ºCrossAttention
2. **Phase 1.4**: æ·»åŠ configé€‰é¡¹
3. **æµ‹è¯•**: è¿è¡ŒåŸºç¡€æµ‹è¯•éªŒè¯åŠŸèƒ½

### å¯é€‰ä¼˜åŒ–:
1. **Phase 2**: å®ç°WeightedFeatureMaps
2. **æ€§èƒ½æµ‹è¯•**: å¯¹æ¯”æ ‡å‡†MAE vs CrossMAE
3. **è°ƒä¼˜**: Hyperparameter tuning

---

## âš ï¸ é‡è¦æç¤º

### Phase 0 vs Phase 1çš„åŒºåˆ«:
- **Phase 0**: æ¶æ„è°ƒæ•´ï¼Œä½†ä»ç”¨self-attentionï¼ˆ**å½“å‰çŠ¶æ€**ï¼‰
- **Phase 1**: çœŸæ­£çš„CrossMAEï¼Œç”¨cross-attentionï¼ˆ**å¾…å®Œæˆ**ï¼‰

### å…³é”®ä¼˜åŠ¿:
âœ… **å‘åå…¼å®¹**: æ¥å£ä¸å˜ï¼Œå¯ä»¥éšæ—¶åˆ‡æ¢å›åŸæ¶æ„
âœ… **æ¸è¿›å¼**: åˆ†é˜¶æ®µå®ç°ï¼Œæ¯é˜¶æ®µå¯ç‹¬ç«‹æµ‹è¯•
âœ… **æ¸…æ™°æ–‡æ¡£**: æ‰€æœ‰æ”¹åŠ¨éƒ½æœ‰è¯¦ç»†æ³¨é‡Š

### é£é™©æ§åˆ¶:
âœ… **åŸä»£ç æœªåŠ¨**: water_fm_smallå®Œå…¨ä¿ç•™
âœ… **ç‹¬ç«‹ä»£ç åº“**: water_fm_small_caå¹¶è¡Œå­˜åœ¨
âœ… **å¯å›æ»š**: æ¯ä¸ªPhaseéƒ½å¯ä»¥ç‹¬ç«‹å›æ»š

---

ç”Ÿæˆæ—¶é—´: 2025-12-25
çŠ¶æ€: Phase 0 å’Œ Phase 1.1 å®Œæˆ âœ…
ä¸‹ä¸€æ­¥: Phase 1.2-1.4 (CrossAttentioné›†æˆ)
