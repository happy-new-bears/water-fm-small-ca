# è·¨æ¨¡æ€Multi-Modal MAEä¿®æ”¹è®¡åˆ’

**æ—¥æœŸ**: 2025-12-25
**ç›®æ ‡**: å°†ç‹¬ç«‹æ¨¡æ€MAEæ”¹é€ ä¸ºè·¨æ¨¡æ€èåˆMAE
**å‚è€ƒ**: CAV-MAE + CrossMAE

---

## ğŸ“‹ æ€»ä½“ç›®æ ‡

å°†å½“å‰çš„**ç‹¬ç«‹æ¨¡æ€MAE**æ”¹é€ ä¸º**è·¨æ¨¡æ€èåˆMAE**ï¼Œå®ç°ï¼š
1. å„æ¨¡æ€æ·»åŠ modality tokensæ ‡è¯†
2. Encoderè¾“å‡ºé€šè¿‡shared transformerèåˆ
3. Decoderæ¥æ”¶èåˆåçš„multi-modal featuresè¿›è¡Œcross-attentioné‡å»º

---

## ğŸ¯ ä¿®æ”¹ä»»åŠ¡åˆ†è§£

### **ä»»åŠ¡1: æ·»åŠ Modality Tokens**

#### 1.1 åœ¨MultiModalMAE.__init__ä¸­å®šä¹‰10ä¸ªmodality tokens

**æ–‡ä»¶**: `models/multimodal_mae.py`
**ä½ç½®**: åœ¨åˆ›å»ºencodersä¹‹å‰ï¼ˆçº¦line 52ä¹‹å‰ï¼‰

**æ–°å¢ä»£ç **:
```python
# ========== Modality Tokens (Encoder) ==========
# 5ä¸ªencoder modality tokens (d_modelç»´åº¦ = 256)
self.modality_precip = nn.Parameter(torch.zeros(1, 1, config.d_model))
self.modality_soil = nn.Parameter(torch.zeros(1, 1, config.d_model))
self.modality_temp = nn.Parameter(torch.zeros(1, 1, config.d_model))
self.modality_evap = nn.Parameter(torch.zeros(1, 1, config.d_model))
self.modality_riverflow = nn.Parameter(torch.zeros(1, 1, config.d_model))

# ========== Decoder Modality Tokens ==========
# 5ä¸ªdecoder modality tokens (decoder_dimç»´åº¦ = 128)
self.decoder_modality_precip = nn.Parameter(torch.zeros(1, 1, config.decoder_dim))
self.decoder_modality_soil = nn.Parameter(torch.zeros(1, 1, config.decoder_dim))
self.decoder_modality_temp = nn.Parameter(torch.zeros(1, 1, config.decoder_dim))
self.decoder_modality_evap = nn.Parameter(torch.zeros(1, 1, config.decoder_dim))
self.decoder_modality_riverflow = nn.Parameter(torch.zeros(1, 1, config.decoder_dim))
```

**åˆå§‹åŒ–**: åœ¨`__init__`æœ«å°¾ï¼ˆåˆ›å»ºæ‰€æœ‰æ¨¡å—åï¼‰æ·»åŠ 
```python
def __init__(self, config, valid_patch_indices=None):
    super().__init__()

    # ... ç°æœ‰çš„åˆå§‹åŒ–ä»£ç  ...

    # ========== Initialize modality tokens ==========
    # Encoder modality tokens
    nn.init.normal_(self.modality_precip, std=0.02)
    nn.init.normal_(self.modality_soil, std=0.02)
    nn.init.normal_(self.modality_temp, std=0.02)
    nn.init.normal_(self.modality_evap, std=0.02)
    nn.init.normal_(self.modality_riverflow, std=0.02)

    # Decoder modality tokens
    nn.init.normal_(self.decoder_modality_precip, std=0.02)
    nn.init.normal_(self.decoder_modality_soil, std=0.02)
    nn.init.normal_(self.decoder_modality_temp, std=0.02)
    nn.init.normal_(self.decoder_modality_evap, std=0.02)
    nn.init.normal_(self.decoder_modality_riverflow, std=0.02)
```

**å‚è€ƒ**: CAV-MAE line 88-89, 111-112, 153-156

---

#### 1.2 ä¿®æ”¹Image Encoderæ¥æ”¶modality_token

**æ–‡ä»¶**: `models/image_encoder.py`

**ä¿®æ”¹1: __init__ç­¾å**ï¼ˆçº¦line 38-50ï¼‰
```python
def __init__(
    self,
    patch_size: int = 10,
    image_hw: Tuple[int, int] = (290, 180),
    d_model: int = 256,
    nhead: int = 8,
    num_layers: int = 6,
    max_time_steps: int = 90,
    dropout: float = 0.1,
    valid_patch_indices: Tensor = None,
    use_weighted_fm: bool = False,
    use_fm_layers: list = None,
    use_input: bool = False,
    modality_token: nn.Parameter = None,  # â­ æ–°å¢å‚æ•°
):
    super().__init__()

    # ... ç°æœ‰åˆå§‹åŒ–ä»£ç  ...

    # â­ å­˜å‚¨modality tokenå¼•ç”¨
    self.modality_token = modality_token
```

**ä¿®æ”¹2: forwardä¸­æ·»åŠ modality token**ï¼ˆçº¦line 213ä¹‹åï¼‰

**å½“å‰ä»£ç **ï¼ˆline 212-213ï¼‰:
```python
# Add both PEs to x (vectorized!)
x = x + spatial_emb + temporal_emb
```

**ä¿®æ”¹ä¸º**:
```python
# Add both PEs to x (vectorized!)
x = x + spatial_emb + temporal_emb

# â­ Add modality token (CAV-MAE style: after pos_embed)
if self.modality_token is not None:
    x = x + self.modality_token  # [1, 1, d_model] broadcast to [B, max_len, d_model]
```

**å‚è€ƒ**: CAV-MAE line 275-276, 279-280

---

#### 1.3 ä¿®æ”¹Vector Encoderæ¥æ”¶modality_token

**æ–‡ä»¶**: `models/vector_encoder.py`

**ä¿®æ”¹1: __init__ç­¾å**ï¼ˆçº¦line 39-52ï¼‰
```python
def __init__(
    self,
    in_feat: int = 1,
    stat_dim: int = 11,
    d_model: int = 256,
    n_layers: int = 4,
    nhead: int = 8,
    dropout: float = 0.1,
    max_len: int = 90,
    use_weighted_fm: bool = False,
    use_fm_layers: list = None,
    use_input: bool = False,
    patch_size: int = 8,
    modality_token: nn.Parameter = None,  # â­ æ–°å¢å‚æ•°
):
    super().__init__()

    # ... ç°æœ‰åˆå§‹åŒ–ä»£ç  ...

    # â­ å­˜å‚¨modality tokenå¼•ç”¨
    self.modality_token = modality_token
```

**ä¿®æ”¹2: forwardä¸­æ·»åŠ modality token**ï¼ˆçº¦line 244ä¹‹åï¼‰

**å½“å‰ä»£ç **ï¼ˆline 242-244ï¼‰:
```python
# ===== Step 5: Flatten time dimension =====
# [B, max_len, T, d_model] -> [B, max_len*T, d_model]
x = x.reshape(B, max_len * T, self.d_model)
```

**ä¿®æ”¹ä¸º**:
```python
# ===== Step 5: Flatten time dimension =====
# [B, max_len, T, d_model] -> [B, max_len*T, d_model]
x = x.reshape(B, max_len * T, self.d_model)

# â­ Add modality token (CAV-MAE style: after pos_embed, before transformer)
if self.modality_token is not None:
    x = x + self.modality_token  # [1, 1, d_model] broadcast to [B, max_len*T, d_model]
```

**ä½ç½®**: åœ¨flattenä¹‹åã€FiLM transformerä¹‹å‰

---

#### 1.4 ä¿®æ”¹MultiModalMAEåˆ›å»ºencoderæ—¶ä¼ å…¥modality_token

**æ–‡ä»¶**: `models/multimodal_mae.py`

**ä¿®æ”¹ä½ç½®**: encoderåˆ›å»ºä»£ç ï¼ˆçº¦line 53-122ï¼‰

**å½“å‰ä»£ç **:
```python
self.precip_encoder = ImageModalityEncoder(
    patch_size=config.patch_size,
    image_hw=(config.image_height, config.image_width),
    d_model=config.d_model,
    nhead=config.nhead,
    num_layers=config.img_encoder_layers,
    max_time_steps=config.max_time_steps,
    dropout=config.dropout,
    valid_patch_indices=self.valid_patch_indices,
    use_weighted_fm=config.use_weighted_fm,
    use_fm_layers=config.use_fm_layers,
    use_input=config.use_input,
)
```

**ä¿®æ”¹ä¸º**:
```python
self.precip_encoder = ImageModalityEncoder(
    patch_size=config.patch_size,
    image_hw=(config.image_height, config.image_width),
    d_model=config.d_model,
    nhead=config.nhead,
    num_layers=config.img_encoder_layers,
    max_time_steps=config.max_time_steps,
    dropout=config.dropout,
    valid_patch_indices=self.valid_patch_indices,
    use_weighted_fm=config.use_weighted_fm,
    use_fm_layers=config.use_fm_layers,
    use_input=config.use_input,
    modality_token=self.modality_precip,  # â­ æ–°å¢
)
```

**ç±»ä¼¼ä¿®æ”¹æ‰€æœ‰5ä¸ªencoder**:
- `self.precip_encoder` â†’ ä¼ å…¥ `self.modality_precip`
- `self.soil_encoder` â†’ ä¼ å…¥ `self.modality_soil`
- `self.temp_encoder` â†’ ä¼ å…¥ `self.modality_temp`
- `self.evap_encoder` â†’ ä¼ å…¥ `self.modality_evap`
- `self.riverflow_encoder` â†’ ä¼ å…¥ `self.modality_riverflow`

---

### **ä»»åŠ¡2: å®ç°Shared Fusion Layers**

#### 2.1 åœ¨MultiModalMAE.__init__ä¸­æ·»åŠ shared transformer

**æ–‡ä»¶**: `models/multimodal_mae.py`
**ä½ç½®**: åœ¨decoderså®šä¹‰ä¹‹å‰ï¼ˆçº¦line 125ä¹‹å‰ï¼‰

**æ–°å¢ä»£ç **:
```python
# ========== Shared Fusion Transformer ==========
# å‚è€ƒCAV-MAEçš„blocks_u (unified branch)
# è®©å¤šä¸ªæ¨¡æ€çš„visible tokensäº’ç›¸äº¤äº’
self.shared_depth = getattr(config, 'shared_depth', 1)  # é»˜è®¤1å±‚

self.blocks_shared = nn.ModuleList([
    nn.TransformerEncoderLayer(
        d_model=config.d_model,
        nhead=config.nhead,
        dim_feedforward=4 * config.d_model,
        dropout=config.dropout,
        batch_first=True,
    )
    for _ in range(self.shared_depth)
])

# Normalization for fused features
self.norm_shared = nn.LayerNorm(config.d_model)
```

**å‚è€ƒ**: CAV-MAE line 99, 302-304

---

#### 2.2 ä¿®æ”¹forwardæ–¹æ³•ï¼Œæ·»åŠ fusionæ­¥éª¤

**æ–‡ä»¶**: `models/multimodal_mae.py`
**ä½ç½®**: åœ¨encoderè°ƒç”¨ä¹‹åã€decoderè°ƒç”¨ä¹‹å‰ï¼ˆçº¦line 220-240ä¹‹é—´ï¼‰

**å½“å‰ä»£ç **:
```python
# ===== Encode all modalities =====
# Image modalities
precip_token, precip_mask_info = self.precip_encoder(
    batch['precip'], batch['precip_mask']
)
soil_token, soil_mask_info = self.soil_encoder(
    batch['soil'], batch['soil_mask']
)
temp_token, temp_mask_info = self.temp_encoder(
    batch['temp'], batch['temp_mask']
)

# Vector modalities (with FiLM)
evap_token, evap_mask_info = self.evap_encoder(
    batch['evap'], batch['static_attr'], batch['evap_mask']
)
riverflow_token, riverflow_mask_info = self.riverflow_encoder(
    batch['riverflow'], batch['static_attr'], batch['riverflow_mask']
)

# ===== Decode all modalities =====
# ...
```

**æ’å…¥fusionä»£ç **ï¼ˆåœ¨encodeå’Œdecodeä¹‹é—´ï¼‰:
```python
# ===== Encode all modalities ===== (ä¿æŒä¸å˜)
# ... encoderè°ƒç”¨ ...

# ===== Shared Fusion Layers ===== (â­ æ–°å¢æ•´ä¸ªsection)
# Step 1: è·å–batch sizeå’Œdevice
B = precip_token.shape[0]
device = precip_token.device

# Step 2: æ‹¼æ¥æ‰€æœ‰æ¨¡æ€çš„visible tokens
# æ³¨æ„: Vector modalityçš„æœ€åä¸€ä¸ªtokenæ˜¯static tokenï¼Œéœ€è¦æ’é™¤
all_tokens = torch.cat([
    precip_token,              # [B, L_precip, d_model]
    soil_token,                # [B, L_soil, d_model]
    temp_token,                # [B, L_temp, d_model]
    evap_token[:, :-1, :],     # [B, L_evap-1, d_model] æ’é™¤static token
    riverflow_token[:, :-1, :] # [B, L_river-1, d_model] æ’é™¤static token
], dim=1)  # [B, L_total, d_model]

# Step 3: åˆ›å»ºpadding mask (æ‹¼æ¥å„è‡ªçš„padding mask)
# ä»mask_infoä¸­è·å–padding_maskï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºå…¨Falseçš„mask
precip_pad = precip_mask_info.get('padding_mask',
    torch.zeros(B, precip_token.shape[1], device=device, dtype=torch.bool))
soil_pad = soil_mask_info.get('padding_mask',
    torch.zeros(B, soil_token.shape[1], device=device, dtype=torch.bool))
temp_pad = temp_mask_info.get('padding_mask',
    torch.zeros(B, temp_token.shape[1], device=device, dtype=torch.bool))
evap_pad = evap_mask_info.get('padding_mask',
    torch.zeros(B, evap_token.shape[1], device=device, dtype=torch.bool))
riverflow_pad = riverflow_mask_info.get('padding_mask',
    torch.zeros(B, riverflow_token.shape[1], device=device, dtype=torch.bool))

# æ’é™¤vector modalityçš„static tokençš„padding (æœ€åä¸€ä¸ªæ˜¯static token)
evap_pad_seq = evap_pad[:, :-1] if evap_pad.shape[1] > 0 else evap_pad
riverflow_pad_seq = riverflow_pad[:, :-1] if riverflow_pad.shape[1] > 0 else riverflow_pad

all_padding_mask = torch.cat([
    precip_pad,
    soil_pad,
    temp_pad,
    evap_pad_seq,
    riverflow_pad_seq
], dim=1)  # [B, L_total]

# Step 4: é€šè¿‡shared transformerè¿›è¡Œè·¨æ¨¡æ€èåˆ
fused_features = all_tokens
for blk in self.blocks_shared:
    fused_features = blk(fused_features, src_key_padding_mask=all_padding_mask)
fused_features = self.norm_shared(fused_features)
# fused_features: [B, L_total, d_model] - èåˆåçš„multi-modal features

# ===== Decode all modalities ===== (éœ€è¦ä¿®æ”¹ï¼Œè§ä»»åŠ¡3)
# ...
```

**å…³é”®ç‚¹**:
1. Vector modalityè¦æ’é™¤static tokenï¼ˆæœ€åä¸€ä¸ªtokenï¼‰
2. æ­£ç¡®æ‹¼æ¥padding masks
3. Shared transformeræ¥æ”¶`src_key_padding_mask`
4. è¾“å‡ºçš„`fused_features`åŒ…å«æ‰€æœ‰æ¨¡æ€çš„èåˆä¿¡æ¯

**å‚è€ƒ**: CAV-MAE line 299-304

---

### **ä»»åŠ¡3: ä¿®æ”¹Decoderæ¥æ”¶fused_features**

#### 3.1 ä¿®æ”¹Image Decoderçš„forwardç­¾å

**æ–‡ä»¶**: `models/image_decoder.py`

**ä¿®æ”¹1: forwardç­¾å**ï¼ˆçº¦line 137ï¼‰

**å½“å‰ä»£ç **:
```python
def forward(self, encoder_output, mask_info: Dict) -> Tensor:
```

**ä¿®æ”¹ä¸º**:
```python
def forward(self, encoder_output, mask_info: Dict, decoder_modality_token=None) -> Tensor:
```

**ä¿®æ”¹2: _forward_cross_attnç­¾åå’Œå®ç°**ï¼ˆçº¦line 149ï¼‰

**å½“å‰ä»£ç **:
```python
def _forward_cross_attn(self, encoder_output, mask_info: Dict) -> Tensor:
```

**ä¿®æ”¹ä¸º**:
```python
def _forward_cross_attn(self, encoder_output, mask_info: Dict, decoder_modality_token=None) -> Tensor:
```

**ä¿®æ”¹3: åœ¨queriesåˆ›å»ºåæ·»åŠ decoder_modality_token**ï¼ˆçº¦line 202ä¹‹åï¼‰

**å½“å‰ä»£ç **ï¼ˆline 191-202ï¼‰:
```python
# Create Queries [B, k, decoder_dim]
queries = self.mask_token.expand(B, num_masked_per_sample, -1).clone()

# Add Spatial PE (Gathering, NO LOOP!)
spatial_emb = self.spatial_pos[0, p_indices]  # [B, k, decoder_dim]
queries = queries + spatial_emb

# Add Temporal PE (Gathering, NO LOOP!)
temporal_emb = self.temporal_pos.pe.squeeze(0)[t_indices]  # [B, k, decoder_dim]
queries = queries + temporal_emb
```

**ä¿®æ”¹ä¸º**:
```python
# Create Queries [B, k, decoder_dim]
queries = self.mask_token.expand(B, num_masked_per_sample, -1).clone()

# Add Spatial PE (Gathering, NO LOOP!)
spatial_emb = self.spatial_pos[0, p_indices]  # [B, k, decoder_dim]
queries = queries + spatial_emb

# Add Temporal PE (Gathering, NO LOOP!)
temporal_emb = self.temporal_pos.pe.squeeze(0)[t_indices]  # [B, k, decoder_dim]
queries = queries + temporal_emb

# â­ Add Decoder Modality Token (CAV-MAE style: after all PEs)
if decoder_modality_token is not None:
    queries = queries + decoder_modality_token  # [1, 1, decoder_dim] broadcast
```

**ä¿®æ”¹4: ä¼ é€’decoder_modality_token**ï¼ˆçº¦line 150ï¼‰

**å½“å‰ä»£ç **:
```python
if self.use_cross_attn:
    return self._forward_cross_attn(encoder_output, mask_info)
```

**ä¿®æ”¹ä¸º**:
```python
if self.use_cross_attn:
    return self._forward_cross_attn(encoder_output, mask_info, decoder_modality_token)
```

**å‚è€ƒ**: CAV-MAE line 338-339

---

#### 3.2 ä¿®æ”¹Vector Decoderçš„forwardç­¾å

**æ–‡ä»¶**: `models/vector_decoder.py`

**å®Œå…¨ç›¸åŒçš„ä¿®æ”¹æ­¥éª¤**ï¼ˆå‚è€ƒ3.1ï¼‰:

1. **forwardç­¾å**æ·»åŠ `decoder_modality_token=None`
2. **_forward_cross_attnç­¾å**æ·»åŠ `decoder_modality_token=None`
3. **åœ¨queriesåˆ›å»ºåæ·»åŠ decoder_modality_token**ï¼ˆçº¦line 195ä¹‹åï¼‰:

```python
# Add Temporal PE (Gathering, NO LOOP!)
temporal_emb = self.temporal_pos.pe.squeeze(0)[t_indices]  # [B, k, decoder_dim]
queries = queries + temporal_emb

# â­ Add Decoder Modality Token (CAV-MAE style: after all PEs)
if decoder_modality_token is not None:
    queries = queries + decoder_modality_token  # [1, 1, decoder_dim] broadcast
```

4. **ä¼ é€’decoder_modality_token**åˆ°`_forward_cross_attn`

---

#### 3.3 ä¿®æ”¹MultiModalMAEçš„decoderè°ƒç”¨

**æ–‡ä»¶**: `models/multimodal_mae.py`
**ä½ç½®**: forwardæ–¹æ³•ä¸­çš„decoderè°ƒç”¨éƒ¨åˆ†ï¼ˆçº¦line 240-248ï¼‰

**å½“å‰ä»£ç **:
```python
# ===== Decode all modalities =====
# Image modalities
precip_pred = self.precip_decoder(precip_token, precip_mask_info)
soil_pred = self.soil_decoder(soil_token, soil_mask_info)
temp_pred = self.temp_decoder(temp_token, temp_mask_info)

# Vector modalities
evap_pred = self.evap_decoder(evap_token, evap_mask_info)
riverflow_pred = self.riverflow_decoder(riverflow_token, riverflow_mask_info)
```

**ä¿®æ”¹ä¸º**:
```python
# ===== Decode all modalities =====
# â­ æ‰€æœ‰decoderç°åœ¨æ¥æ”¶fused_featuresï¼ˆè€Œéå•æ¨¡æ€tokenï¼‰

# Image modalities
precip_pred = self.precip_decoder(
    fused_features,                          # â­ æ”¹ä¸ºfused_features
    precip_mask_info,
    decoder_modality_token=self.decoder_modality_precip  # â­ æ–°å¢
)
soil_pred = self.soil_decoder(
    fused_features,                          # â­ æ”¹ä¸ºfused_features
    soil_mask_info,
    decoder_modality_token=self.decoder_modality_soil  # â­ æ–°å¢
)
temp_pred = self.temp_decoder(
    fused_features,                          # â­ æ”¹ä¸ºfused_features
    temp_mask_info,
    decoder_modality_token=self.decoder_modality_temp  # â­ æ–°å¢
)

# Vector modalities
evap_pred = self.evap_decoder(
    fused_features,                          # â­ æ”¹ä¸ºfused_features
    evap_mask_info,
    decoder_modality_token=self.decoder_modality_evap  # â­ æ–°å¢
)
riverflow_pred = self.riverflow_decoder(
    fused_features,                          # â­ æ”¹ä¸ºfused_features
    riverflow_mask_info,
    decoder_modality_token=self.decoder_modality_riverflow  # â­ æ–°å¢
)
```

**å…³é”®å˜åŒ–**:
1. æ‰€æœ‰decoderæ¥æ”¶`fused_features`ï¼ˆåŒ…å«æ‰€æœ‰æ¨¡æ€çš„èåˆä¿¡æ¯ï¼‰
2. ä¼ å…¥å¯¹åº”çš„`decoder_modality_token`ï¼ˆå‘Šè¯‰decoderè¦é‡å»ºå“ªä¸ªæ¨¡æ€ï¼‰

---

## ğŸ“Š ä¿®æ”¹æ€»ç»“è¡¨

| ä»»åŠ¡ | æ–‡ä»¶ | ä¿®æ”¹ç±»å‹ | é¢„è®¡è¡Œæ•° |
|------|------|---------|---------|
| 1.1 å®šä¹‰10ä¸ªmodality tokens | `multimodal_mae.py` | æ–°å¢__init__ | ~25è¡Œ |
| 1.2 ä¿®æ”¹ImageEncoder | `image_encoder.py` | ä¿®æ”¹__init__ + forward | ~8è¡Œ |
| 1.3 ä¿®æ”¹VectorEncoder | `vector_encoder.py` | ä¿®æ”¹__init__ + forward | ~8è¡Œ |
| 1.4 åˆ›å»ºencoderæ—¶ä¼ å…¥token | `multimodal_mae.py` | ä¿®æ”¹__init__ | ~5è¡ŒÃ—5 |
| 2.1 å®šä¹‰shared transformer | `multimodal_mae.py` | æ–°å¢__init__ | ~15è¡Œ |
| 2.2 å®ç°fusioné€»è¾‘ | `multimodal_mae.py` | ä¿®æ”¹forward | ~50è¡Œ |
| 3.1 ä¿®æ”¹ImageDecoder | `image_decoder.py` | ä¿®æ”¹forward | ~10è¡Œ |
| 3.2 ä¿®æ”¹VectorDecoder | `vector_decoder.py` | ä¿®æ”¹forward | ~10è¡Œ |
| 3.3 ä¿®æ”¹decoderè°ƒç”¨ | `multimodal_mae.py` | ä¿®æ”¹forward | ~20è¡Œ |

**æ€»è®¡**: çº¦156è¡Œä»£ç ä¿®æ”¹

---

## âš ï¸ å…³é”®æ³¨æ„äº‹é¡¹

### 1. **Vector Modalityçš„Static Tokenå¤„ç†**
```python
# âŒ é”™è¯¯ï¼šåŒ…å«static token
all_tokens = torch.cat([precip_token, ..., evap_token], dim=1)

# âœ… æ­£ç¡®ï¼šæ’é™¤static token
all_tokens = torch.cat([precip_token, ..., evap_token[:, :-1, :]], dim=1)
```

### 2. **Modality Tokenæ·»åŠ é¡ºåº**
å‚è€ƒCAV-MAE (line 274-276):
```python
x = patch_embed(x)
x = x + pos_embed       # å…ˆåŠ ä½ç½®ç¼–ç 
x = x + modality_token  # å†åŠ æ¨¡æ€æ ‡è¯†
```

### 3. **Decoder Modality Tokenæ·»åŠ é¡ºåº**
å‚è€ƒCAV-MAE (line 336-339):
```python
queries = mask_token + spatial_PE + temporal_PE + decoder_modality_token
```
é¡ºåºï¼šmask_token â†’ spatial PE â†’ temporal PE â†’ modality token

### 4. **Padding Maskçš„æ­£ç¡®æ‹¼æ¥**
- å„æ¨¡æ€çš„visible lengthsä¸åŒ
- Vector modalityè¦æ’é™¤static tokençš„padding
- Shared transformeréœ€è¦æ­£ç¡®çš„`src_key_padding_mask`

### 5. **Configä¿®æ”¹**
éœ€è¦åœ¨`configs/mae_config.py`ä¸­æ·»åŠ :
```python
@dataclass
class MAEConfig:
    # ... ç°æœ‰é…ç½® ...

    # â­ æ–°å¢ï¼šShared fusion transformer layers
    shared_depth: int = 1  # Number of shared fusion transformer layers
```

---

## ğŸ” æµ‹è¯•éªŒè¯è®¡åˆ’

ä¿®æ”¹å®Œæˆåéœ€è¦éªŒè¯çš„å†…å®¹ï¼š

### **1. å‚æ•°æ£€æŸ¥**
```python
import torch
from models.multimodal_mae import MultiModalMAE

model = MultiModalMAE(config)

# æ£€æŸ¥modality tokenså­˜åœ¨
assert hasattr(model, 'modality_precip')
assert hasattr(model, 'decoder_modality_precip')
# ... æ£€æŸ¥å…¶ä»–8ä¸ª

# æ£€æŸ¥shared transformerå­˜åœ¨
assert hasattr(model, 'blocks_shared')
assert len(model.blocks_shared) == config.shared_depth

print("âœ“ All parameters exist")
```

### **2. Forward Passæµ‹è¯•**
```python
# åˆ›å»ºæµ‹è¯•æ•°æ®
batch = {
    'precip': torch.randn(2, 90, 290, 180),
    'soil': torch.randn(2, 90, 290, 180),
    'temp': torch.randn(2, 90, 290, 180),
    'evap': torch.randn(2, 604, 90),
    'riverflow': torch.randn(2, 604, 90),
    'static_attr': torch.randn(2, 604, 11),
    'precip_mask': torch.rand(2, 90, 522) < 0.75,
    'soil_mask': torch.rand(2, 90, 522) < 0.75,
    'temp_mask': torch.rand(2, 90, 522) < 0.75,
    'evap_mask': torch.rand(2, 76, 90) < 0.75,
    'riverflow_mask': torch.rand(2, 76, 90) < 0.75,
}

# Forward pass
total_loss, loss_dict = model(batch)

print(f"âœ“ Total loss: {total_loss.item():.4f}")
print(f"âœ“ Loss dict: {loss_dict}")
```

### **3. æ¢¯åº¦æ£€æŸ¥**
```python
# Backward
total_loss.backward()

# æ£€æŸ¥modality tokensæœ‰æ¢¯åº¦
assert model.modality_precip.grad is not None
assert model.decoder_modality_precip.grad is not None
print("âœ“ Modality tokens have gradients")

# æ£€æŸ¥shared transformeræœ‰æ¢¯åº¦
for param in model.blocks_shared.parameters():
    assert param.grad is not None
print("âœ“ Shared transformer has gradients")
```

### **4. Shapeæ£€æŸ¥**
```python
# åœ¨forwardä¸­æ·»åŠ debug print
print(f"Fused features shape: {fused_features.shape}")
# åº”è¯¥æ˜¯ [B, L_total, d_model]

print(f"Precip pred shape: {precip_pred.shape}")
# åº”è¯¥æ˜¯ [B, T, num_patches, patch_dim]
```

---

## ğŸ“ ä¿®æ”¹é¡ºåºå»ºè®®

å»ºè®®æŒ‰ä»¥ä¸‹é¡ºåºä¿®æ”¹ï¼Œæ¯æ­¥éªŒè¯åå†è¿›è¡Œä¸‹ä¸€æ­¥ï¼š

1. âœ… **ç¬¬ä¸€æ­¥**: æ·»åŠ modality tokenså®šä¹‰å’Œåˆå§‹åŒ–
   - ä¿®æ”¹`multimodal_mae.py`çš„`__init__`
   - æµ‹è¯•ï¼šå‚æ•°æ˜¯å¦å­˜åœ¨

2. âœ… **ç¬¬äºŒæ­¥**: ä¿®æ”¹Encoderæ¥æ”¶modality_token
   - ä¿®æ”¹`image_encoder.py`å’Œ`vector_encoder.py`
   - ä¿®æ”¹`multimodal_mae.py`åˆ›å»ºencoderæ—¶ä¼ å…¥token
   - æµ‹è¯•ï¼šforwardæ˜¯å¦æ­£å¸¸

3. âœ… **ç¬¬ä¸‰æ­¥**: æ·»åŠ shared transformer
   - ä¿®æ”¹`multimodal_mae.py`çš„`__init__`
   - æµ‹è¯•ï¼šå‚æ•°æ˜¯å¦å­˜åœ¨

4. âœ… **ç¬¬å››æ­¥**: å®ç°fusioné€»è¾‘
   - ä¿®æ”¹`multimodal_mae.py`çš„`forward`
   - æµ‹è¯•ï¼šfusionåçš„shapeæ˜¯å¦æ­£ç¡®

5. âœ… **ç¬¬äº”æ­¥**: ä¿®æ”¹Decoderç­¾å
   - ä¿®æ”¹`image_decoder.py`å’Œ`vector_decoder.py`
   - æ”¯æŒ`decoder_modality_token`å‚æ•°ï¼ˆé»˜è®¤Noneï¼Œå…¼å®¹æ—§ä»£ç ï¼‰
   - æµ‹è¯•ï¼šforwardæ˜¯å¦æ­£å¸¸

6. âœ… **ç¬¬å…­æ­¥**: ä¿®æ”¹decoderè°ƒç”¨
   - ä¿®æ”¹`multimodal_mae.py`çš„`forward`
   - ä¼ å…¥`fused_features`å’Œ`decoder_modality_token`
   - æµ‹è¯•ï¼šå®Œæ•´forward + backward

7. âœ… **ç¬¬ä¸ƒæ­¥**: å®Œæ•´æµ‹è¯•
   - è¿è¡Œtraining script
   - æ£€æŸ¥lossæ˜¯å¦ä¸‹é™
   - æ£€æŸ¥wandbæ—¥å¿—

---

## ğŸ’¡ è®¾è®¡ç†å¿µæ€»ç»“

### **ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ**

1. **Encoder Modality Token**:
   - è®©encoderçŸ¥é“è‡ªå·±å¤„ç†çš„æ˜¯ä»€ä¹ˆæ¨¡æ€
   - åœ¨shared transformerä¸­åŒºåˆ†ä¸åŒæ¨¡æ€çš„tokens

2. **Shared Fusion Transformer**:
   - è®©ä¸åŒæ¨¡æ€çš„visible tokensäº’ç›¸äº¤äº’
   - å­¦ä¹ è·¨æ¨¡æ€çš„ä¾èµ–å…³ç³»
   - ä¾‹å¦‚ï¼šé™æ°´å’Œæ¸©åº¦çš„è”åˆæ¨¡å¼

3. **Decoder Modality Token**:
   - å‘Šè¯‰decoderè¦é‡å»ºå“ªä¸ªæ¨¡æ€
   - å¸®åŠ©decoderå­¦ä¹ æ¨¡æ€ç‰¹å®šçš„é‡å»ºç­–ç•¥
   - ä¾‹å¦‚ï¼šé‡å»ºé™æ°´vsé‡å»ºæ¸©åº¦éœ€è¦ä¸åŒçš„ç­–ç•¥

4. **Cross-Attention Decoder**:
   - Queriesæ¥è‡ªmasked positionsï¼ˆè¦é‡å»ºçš„éƒ¨åˆ†ï¼‰
   - Keys/Valuesæ¥è‡ªfused_featuresï¼ˆæ‰€æœ‰æ¨¡æ€çš„èåˆä¿¡æ¯ï¼‰
   - æ¯ä¸ªmasked positionå¯ä»¥ä»æ‰€æœ‰æ¨¡æ€è·å–ä¿¡æ¯

### **ä¸CAV-MAEå’ŒCrossMAEçš„å¯¹æ¯”**

| ç»´åº¦ | CAV-MAE | CrossMAE | æˆ‘ä»¬çš„è®¾è®¡ |
|------|---------|----------|-----------|
| **Encoder** | æ¨¡æ€ç‰¹å®š + Shared | å•æ¨¡æ€ViT | æ¨¡æ€ç‰¹å®š + Shared âœ… |
| **Modality Token** | âœ… æœ‰ | âŒ æ—  | âœ… æœ‰ï¼ˆ5ä¸ªæ¨¡æ€ï¼‰ |
| **Decoderè¾“å…¥** | All tokens (V+M) | Only masked | Only masked âœ… |
| **Decoderæœºåˆ¶** | Self-Attention | Cross-Attention | Cross-Attention âœ… |
| **Keys/Values** | å„è‡ªæ¨¡æ€ | å•æ¨¡æ€visible | **æ‰€æœ‰æ¨¡æ€fusion** âœ… |

**æˆ‘ä»¬çš„åˆ›æ–°ç‚¹**ï¼š
- âœ… CAV-MAEçš„å¤šæ¨¡æ€encoderèåˆæœºåˆ¶
- âœ… CrossMAEçš„é«˜æ•ˆcross-attention decoder
- âœ… **èåˆä¸¤è€…ä¼˜ç‚¹**ï¼šdecoderçš„K/Væ¥è‡ªmulti-modal fused features

---

## ğŸ“ å‚è€ƒæ–‡çŒ®

1. **CAV-MAE**: Contrastive Audio-Visual Masked Autoencoder
   - æ–‡ä»¶ï¼š`/Users/transformer/Desktop/water_code/cav-mae-master/src/models/cav_mae.py`
   - å…³é”®è®¾è®¡ï¼šModality tokens, Shared transformer layers

2. **CrossMAE**: Cross-Attention Masked Autoencoders
   - æ–‡ä»¶ï¼š`/Users/transformer/Desktop/water_code/CrossMAE-main/models_cross.py`
   - å…³é”®è®¾è®¡ï¼šCross-attention decoder, Only masked queries

---

## âœ… å®Œæˆæ ‡å‡†

ä¿®æ”¹å®Œæˆåï¼Œéœ€è¦æ»¡è¶³ä»¥ä¸‹æ‰€æœ‰æ¡ä»¶ï¼š

- [ ] 10ä¸ªmodality tokensæ­£ç¡®å®šä¹‰å’Œåˆå§‹åŒ–
- [ ] Encoderæ­£ç¡®æ¥æ”¶å’Œæ·»åŠ modality tokens
- [ ] Shared transformeræ­£ç¡®å®ç°
- [ ] Fusioné€»è¾‘æ­£ç¡®ï¼ˆæ’é™¤vector static tokenï¼‰
- [ ] Decoderæ­£ç¡®æ¥æ”¶decoder_modality_token
- [ ] Decoderæ­£ç¡®æ¥æ”¶fused_features
- [ ] Forward passæˆåŠŸ
- [ ] Backward passæˆåŠŸï¼ˆæ‰€æœ‰å‚æ•°æœ‰æ¢¯åº¦ï¼‰
- [ ] Lossèƒ½æ­£å¸¸è®¡ç®—
- [ ] å®Œæ•´è®­ç»ƒèƒ½è¿è¡Œ

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2025-12-25
