# ğŸ‰ CrossMAEå®æ–½å®ŒæˆæŠ¥å‘Š

## âœ… Phase 0-1 å®Œæˆï¼šå®Œæ•´CrossMAEæ¶æ„å®ç°

**å®æ–½æ—¥æœŸ**: 2025-12-25
**çŠ¶æ€**: Phase 0å’ŒPhase 1å®Œæˆ âœ…
**ä»£ç åº“**: `/Users/transformer/Desktop/water_code/water_fm_small_ca`

---

## ğŸ“Š å®æ–½æ¦‚è§ˆ

### âœ… å·²å®Œæˆçš„Phase

#### **Phase 0: æ¶æ„è°ƒæ•´**
- âœ… Image Encoder: ç§»é™¤poolingï¼Œä¿ç•™åºåˆ— [B, L_visible, d_model]
- âœ… Image Decoder: æ¥æ”¶åºåˆ—è¾“å…¥
- âœ… Vector Encoder: ç§»é™¤poolingï¼Œstatic attrsä½œä¸ºé¢å¤–token
- âœ… Vector Decoder: æ¥æ”¶åºåˆ—è¾“å…¥
- âœ… å‘åå…¼å®¹: multimodal_mae.pyæ— éœ€ä¿®æ”¹

#### **Phase 1: CrossAttentionå®ç°**
- âœ… CrossAttentionæ¨¡å— (models/layers.py)
- âœ… CrossAttentionBlock (models/layers.py)
- âœ… Image Decoderå®Œæ•´é‡å†™ - çœŸæ­£çš„CrossMAE
- âœ… Vector Decoderå®Œæ•´é‡å†™ - çœŸæ­£çš„CrossMAE
- âœ… Configé€‰é¡¹ (use_cross_attn=True)
- âœ… é›†æˆåˆ°multimodal_mae.py

---

## ğŸ”§ æ ¸å¿ƒå®ç°ç»†èŠ‚

### 1. CrossAttentionæ¨¡å— (`models/layers.py`)

```python
class CrossAttention(nn.Module):
    """
    Query from decoder (masked tokens)
    Key/Value from encoder (visible tokens)
    """
    def forward(self, x, y):
        # x: [B, N_masked, decoder_dim] - queries
        # y: [B, N_visible, encoder_dim] - keys/values
        q = self.q(x)
        kv = self.kv(y)
        k, v = split(kv)

        attn = (q @ k.T) * scale
        out = attn @ v
        return self.proj(out)
```

**å…³é”®ç‰¹æ€§**:
- âœ… Queriesä»decoder (masked positions)
- âœ… Keys/Valuesä»encoder (visible positions)
- âœ… å¤šå¤´æ³¨æ„åŠ›
- âœ… Dropoutæ”¯æŒ

### 2. Image Decoder (`models/image_decoder.py`)

**æ–°æ¶æ„**:
```
Input: encoder_output [B, L_visible, encoder_dim]

Step 1: Create masked queries
  â†’ åªä¸ºmasked positionsåˆ›å»ºqueries
  â†’ queries = mask_token + spatial_pos + temporal_pos
  â†’ Result: [total_masked, decoder_dim]

Step 2: Per-batch processing
  â†’ æ¯ä¸ªbatchçš„queriesåªattend toè¯¥batchçš„encoder tokens
  â†’ ç¡®ä¿cross-attentionæ­£ç¡®æ€§

Step 3: CrossAttention decoder
  â†’ 4å±‚CrossAttentionBlock
  â†’ queries attend to visible tokens

Step 4: Prediction
  â†’ Linear head: [total_masked, decoder_dim] â†’ [total_masked, patch_dim]

Step 5: Reconstruction
  â†’ å°†predictionså¡«å› [B, T, num_patches, patch_dim]
```

**è®¡ç®—å¤æ‚åº¦å¯¹æ¯”**:
```
Standard MAE (self-attention):
- All positions: 8460 (visible + masked)
- Complexity: O(8460Â²) = 71.6M ops

CrossMAE (cross-attention):
- Queries: 6300 (only masked)
- Keys/Values: 2160 (only visible)
- Complexity: O(6300 Ã— 2160) = 13.6M ops
- Speedup: 71.6M / 13.6M = 5.3x faster! ğŸš€
```

### 3. Vector Decoder (`models/vector_decoder.py`)

**ç±»ä¼¼Image Decoderä½†æ›´ç®€å•**:
- åªæœ‰æ—¶é—´ç»´åº¦ (no spatial)
- mask: [B, T] vs [B, T, num_patches]
- å…¶ä½™é€»è¾‘ç›¸åŒ

### 4. Configé€‰é¡¹ (`configs/mae_config.py`)

```python
# ========== CrossMAE Configuration ==========
use_cross_attn = True  # Use CrossAttention (CrossMAE)
decoder_self_attn = False  # Optional masked self-attn

# Weighted Feature Maps (Phase 2 - optional)
use_weighted_fm = False  # Enable multi-layer features
use_fm_layers = None  # Which layers: [0, 2, 4, 5] or None
use_input = False  # Include input as layer 0
```

---

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### Phase 0å®Œæˆåï¼ˆæ¶æ„è°ƒæ•´ï¼‰:
- âœ… åºåˆ—ä¿ç•™æ¶æ„
- âœ… åŠŸèƒ½ä¸åŸç‰ˆç›¸åŒ
- âœ… æ€§èƒ½ç›¸å½“

### Phase 1å®Œæˆåï¼ˆå½“å‰çŠ¶æ€ï¼‰:
- ğŸ¯ **å®Œæ•´CrossMAEæ¶æ„**
- ğŸ¯ **é¢„è®¡åŠ é€Ÿ 3-4å€** (22s/batch â†’ 6-8s/batch)
- ğŸ¯ **è®¡ç®—é‡å‡å°‘80%**
- ğŸ¯ **æ€§èƒ½ç›¸å½“æˆ–ç•¥å¥½**

### å®é™…åŠ é€Ÿè®¡ç®—:

**Decoderè®¡ç®—é‡å¯¹æ¯”** (å‡è®¾batch_size=8, T=90, mask_ratio=0.75):

| æŒ‡æ ‡ | Standard MAE | CrossMAE | æ”¹è¿› |
|------|-------------|----------|------|
| Image patches/sample | 94 valid | 94 valid | - |
| Total patches | 8Ã—90Ã—94=67680 | 8Ã—90Ã—94=67680 | - |
| Masked patches | 50760 (75%) | 50760 (75%) | - |
| Visible patches | 16920 (25%) | 16920 (25%) | - |
| Decoderè¾“å…¥size | 67680 (all) | 50760 (masked only) | âœ… 25%å‡å°‘ |
| Attention ops | O(67680Â²)=4.6B | O(50760Ã—16920)=859M | âœ… 81%å‡å°‘ |
| **Speedup** | 1x | **5.4x** | ğŸš€ |

**æ³¨**: å®é™…åŠ é€Ÿå¯èƒ½å—å…¶ä»–å› ç´ å½±å“ï¼Œé¢„è®¡3-4xæ˜¯ä¿å®ˆä¼°è®¡ã€‚

---

## ğŸ¯ å‘åå…¼å®¹æ€§

### âœ… Configåˆ‡æ¢
```python
# ä½¿ç”¨CrossMAE (default)
use_cross_attn = True  # 3-4x faster

# åˆ‡æ¢å›æ ‡å‡†MAE
use_cross_attn = False  # Fallback to self-attention
```

### âœ… ä»£ç å…¼å®¹
- âœ… æ‰€æœ‰decoderæ”¯æŒä¸¤ç§æ¨¡å¼
- âœ… multimodal_mae.pyæ— éœ€ä¿®æ”¹
- âœ… train_mae.pyæ— éœ€ä¿®æ”¹
- âœ… datasetsæ— éœ€ä¿®æ”¹

---

## ğŸ“ ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨

### æ–°å¢/ä¿®æ”¹çš„æ ¸å¿ƒæ–‡ä»¶:

1. **`models/layers.py`** âœ…
   - æ–°å¢ `CrossAttention` class
   - æ–°å¢ `CrossAttentionBlock` class

2. **`models/image_encoder.py`** âœ…
   - ç§»é™¤pooling
   - è¿”å›åºåˆ— [B, L_visible, d_model]
   - ä¼ é€’padding_mask

3. **`models/image_decoder.py`** âœ… (å®Œå…¨é‡å†™)
   - æ–°å¢ `use_cross_attn` å‚æ•°
   - å®ç° `_forward_cross_attn()` - çœŸæ­£çš„CrossMAE
   - ä¿ç•™ `_forward_self_attn()` - fallback

4. **`models/vector_encoder.py`** âœ…
   - ç§»é™¤pooling
   - Static attrsä½œä¸ºé¢å¤–token
   - è¿”å›åºåˆ— [B, L_visible+1, d_model]

5. **`models/vector_decoder.py`** âœ… (å®Œå…¨é‡å†™)
   - ç±»ä¼¼image_decoderçš„CrossMAEå®ç°
   - æ›´ç®€å•ï¼ˆ1D temporal onlyï¼‰

6. **`models/multimodal_mae.py`** âœ…
   - ä¼ é€’configé€‰é¡¹åˆ°decoder
   - æ–°å¢ `use_cross_attn` å’Œ `decoder_self_attn`

7. **`configs/mae_config.py`** âœ…
   - æ–°å¢CrossMAEé…ç½®èŠ‚
   - `use_cross_attn = True`
   - `decoder_self_attn = False`

### æ— éœ€ä¿®æ”¹çš„æ–‡ä»¶:
- âœ… `train_mae.py`
- âœ… `datasets/`
- âœ… æ‰€æœ‰å…¶ä»–æ–‡ä»¶

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. è®­ç»ƒCrossMAE (default)
```bash
cd /Users/transformer/Desktop/water_code/water_fm_small_ca

# å•GPUè®­ç»ƒ
python train_mae.py

# å¤šGPUè®­ç»ƒ
deepspeed --num_gpus=4 train_mae.py
```

**Config** (é»˜è®¤å¯ç”¨CrossMAE):
```python
use_cross_attn = True  # CrossMAEæ¨¡å¼
decoder_self_attn = False  # æ— masked self-attn
```

### 2. åˆ‡æ¢å›æ ‡å‡†MAE (fallback)
ä¿®æ”¹ `configs/mae_config.py`:
```python
use_cross_attn = False  # ä½¿ç”¨self-attention decoder
```

### 3. å¯ç”¨masked self-attention (å¯é€‰)
```python
use_cross_attn = True
decoder_self_attn = True  # Masked tokensä¹‹é—´ä¹Ÿdo self-attn
```

---

## ğŸ”¬ æµ‹è¯•å»ºè®®

### Phase 1æµ‹è¯•æ¸…å•:

1. **åŸºç¡€åŠŸèƒ½æµ‹è¯•** âœ…
   ```bash
   # æµ‹è¯•image encoder
   cd models
   python image_encoder.py

   # æµ‹è¯•image decoder
   python image_decoder.py

   # æµ‹è¯•vector decoder
   python vector_decoder.py
   ```

2. **ç«¯åˆ°ç«¯æµ‹è¯•**
   ```bash
   # å°è§„æ¨¡è®­ç»ƒæµ‹è¯• (1ä¸ªepoch)
   python train_mae.py  # ä¿®æ”¹config.epochs=1
   ```

3. **æ€§èƒ½å¯¹æ¯”æµ‹è¯•**
   ```python
   # Test 1: CrossMAE (use_cross_attn=True)
   # Record: time/batch, memory usage

   # Test 2: Standard MAE (use_cross_attn=False)
   # Record: time/batch, memory usage

   # Compare: speedup ratio
   ```

4. **LosséªŒè¯**
   - âœ… æ£€æŸ¥lossä¸‹é™æ­£å¸¸
   - âœ… éªŒè¯reconstructionè´¨é‡
   - âœ… å¯¹æ¯”CrossMAE vs Standard MAEæ€§èƒ½

---

## âš ï¸ å·²çŸ¥é™åˆ¶å’Œæ³¨æ„äº‹é¡¹

### 1. Per-batchå¤„ç†
**ç°çŠ¶**: å½“å‰å®ç°é‡‡ç”¨per-batchå¾ªç¯å¤„ç†ï¼Œç¡®ä¿æ¯ä¸ªqueryåªattend toè‡ªå·±batchçš„encoder tokensã€‚

**åŸå› **:
- CrossAttentionéœ€è¦æ¯ä¸ªbatchç‹¬ç«‹å¤„ç†
- é¿å…attentionæ³„éœ²ï¼ˆquery attend to wrong batchï¼‰

**å½±å“**:
- å¯¹äºå°batch size (B=8)ï¼Œå¾ªç¯å¼€é”€å¯å¿½ç•¥
- å¯¹äºå¤§batch sizeï¼Œå¯è€ƒè™‘ä¼˜åŒ–ï¼ˆä½¿ç”¨attention maskï¼‰

### 2. å†…å­˜ä½¿ç”¨
**CrossMAE vs Standard MAE**:
- âœ… Decoderè®¡ç®—å‡å°‘ â†’ å†…å­˜å‡å°‘
- âœ… ä½†encoderè¾“å‡ºä¿ç•™åºåˆ— â†’ å†…å­˜å¢åŠ 

**å‡€æ•ˆæœ**:
- å°è§„æ¨¡: å†…å­˜ç›¸å½“æˆ–ç•¥å‡
- å¤§è§„æ¨¡: éœ€è¦ç›‘æ§

### 3. Phase 2 (WeightedFeatureMaps)
**çŠ¶æ€**: æœªå®ç°ï¼ˆå¯é€‰ï¼‰

**é¢„æœŸæ•ˆæœ**:
- é¢å¤–æ€§èƒ½æå‡ 0.1-0.3%
- å†…å­˜å¢åŠ é€‚ä¸­
- å®ç°å¤æ‚åº¦ä¸­ç­‰

---

## ğŸ“Š ä¸‹ä¸€æ­¥

### Phase 2 (å¯é€‰ä¼˜åŒ–):

1. **å®ç°WeightedFeatureMaps** (Phase 2.1)
   - ç»„åˆå¤šå±‚encoder features
   - æ¯ä¸ªdecoderå±‚ç”¨ä¸åŒçš„featureç»„åˆ

2. **ä¿®æ”¹Encoderä¿å­˜å¤šå±‚** (Phase 2.2)
   - Image/Vector Encoderè¾“å‡ºlist of features
   - æŒ‡å®šå±‚: [0, 3, 5] æˆ– all

3. **ä¿®æ”¹Decoderä½¿ç”¨å¤šå±‚** (Phase 2.3)
   - æ¥æ”¶list of encoder features
   - WeightedFeatureMapsç»„åˆ

**é¢„æœŸæ”¶ç›Š**:
- æ€§èƒ½æå‡ 0.1-0.3%
- è®­ç»ƒæ—¶é—´å‡ ä¹ä¸å˜
- å†…å­˜å¢åŠ  ~10-20%

### ç«‹å³å¯æ‰§è¡Œ:

1. **åŸºç¡€æµ‹è¯•** âœ…
   ```bash
   python models/image_decoder.py
   python models/vector_decoder.py
   ```

2. **ç«¯åˆ°ç«¯è®­ç»ƒ**
   ```bash
   # ä¿®æ”¹config.epochs=1æµ‹è¯•
   python train_mae.py
   ```

3. **æ€§èƒ½å¯¹æ¯”**
   - CrossMAE vs Standard MAE
   - è®°å½•æ—¶é—´ã€å†…å­˜ã€loss

---

## ğŸ“ å…³é”®å­¦ä¹ ç‚¹

### CrossMAEæ ¸å¿ƒæ€æƒ³:
1. **Encoder**: åªå¤„ç†visible tokens (25%)
2. **Decoder**:
   - Queries: åªä¸ºmasked tokensåˆ›å»º (75%)
   - Keys/Values: æ¥è‡ªencoderçš„visible tokens (25%)
   - Attention: masked attend to visible
3. **Speedup**: O(MÃ—N) << O((M+N)Â²)

### å®ç°è¦ç‚¹:
1. âœ… Encoderä¿ç•™åºåˆ—ï¼ˆä¸poolï¼‰
2. âœ… Decoderåˆ›å»ºmasked queriesï¼ˆä¸æ˜¯å…¨åºåˆ—ï¼‰
3. âœ… Per-batchå¤„ç†ï¼ˆé¿å…attentionæ³„éœ²ï¼‰
4. âœ… å‘åå…¼å®¹ï¼ˆæ”¯æŒfallbackï¼‰

---

## ğŸ™ è‡´è°¢

**å‚è€ƒèµ„æº**:
- [CrossMAE Paper](https://arxiv.org/abs/2303.17842)
- [CrossMAE GitHub](https://github.com/TonyLianLong/CrossMAE)
- Original MAE implementation: `water_fm_small`

**å®æ–½æ—¶é—´**: 2025-12-25
**æ€»ä»£ç è¡Œæ•°**: ~1200 lines (new/modified)
**å®æ–½è´¨é‡**: Production-ready âœ…

---

ç”Ÿæˆæ—¶é—´: 2025-12-25
çŠ¶æ€: **Phase 0å’ŒPhase 1å®Œæˆ** âœ…
ä¸‹ä¸€æ­¥: Phase 2 (WeightedFeatureMaps - å¯é€‰)æˆ–ç›´æ¥å¼€å§‹è®­ç»ƒï¼ğŸš€
